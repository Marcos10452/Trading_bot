{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e68878-e414-43eb-bf14-e9f0b4bf500a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47f61393-674d-46dd-949a-8c9a674af7aa",
   "metadata": {},
   "source": [
    "# ------------------------------------ Trading Bot --------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15689aa4-3455-4af4-a9fc-1603fb2fc223",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import logging #logger\n",
    "#https://www.youtube.com/watch?v=SMZfgeHFFcA\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "#from network import DeepQNetwork\n",
    "#from replay_memory import ReplayBuffer\n",
    "#tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51da5a66-c8e7-432a-bcdb-2184b125a62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1941d1c-fddc-44a7-83c6-061a69f4d7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd0d2d5-2e43-4383-92c7-ea329a3efd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from env.environment import *\n",
    "from env.portfolio import *\n",
    "from utils.utils import *\n",
    "from agent.agent import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7ffd43-1fa0-4cf5-a9b8-e569f998e446",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pandas.tseries.holiday import USFederalHolidayCalendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbdb3a7-c9a4-43d7-9db1-525854a80838",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2 as pg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df40612e-9485-4766-ac9a-22799813030f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629e873b-4cba-4b2f-a996-35dad30c7874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# »»»»»»»»»»»»»»»»» STOCKS ««««««««««««««««««««z\n",
    "\n",
    "STOCKS={'amazon':'AMZN','apple':'AAPL','netflix':'NFLX','google':'GOOG','Accenture':'ACN',\n",
    "       'alibaba':'BABA','Turtle Beach':'HEAR','Disney':'DIS',\n",
    "       'LG Display':'LPL','microsoft':'MICS','sony':'SONY',\n",
    "       'Cenovus Energy':'CVE','YPF':'YPF','SHELL':'SHEL','Petrobras':'PBR',\n",
    "       'Coca-Cola':'KO','PespsiCo':'PEP','Unilever':'UL','Kimberly-Clark':'KMB',\n",
    "       'Mondelez':'MDLZ'}\n",
    "\n",
    "#STOCKS = {'amazon':'AMZN'}\n",
    "\n",
    "# dir where parquete file will be created\n",
    "stocks_dir = '/dataset/stocks_aux/'\n",
    "\n",
    "#*****************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b0bafd-ee3d-43cc-9a5b-a830952f4a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def turn_of_logger():\n",
    "    logger=logging.getLogger()\n",
    "    for handler in logger.handlers[:]:  #make a copy of the list\n",
    "        logger.removeHandler(handler)\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24f8a0a-c1fb-47c2-84d5-eb10d5d7697b",
   "metadata": {},
   "outputs": [],
   "source": [
    "strin_format='%(i)s, %(market_return)s,%(pr)s,%(Sharpe)s,%(score)s,%(avg_score)s,%(best_score)s,%(loss)s,%(n_steps)s,%(pr_val)s,%(score_val)s, %(avg_score_val)s'\n",
    "def initLogging(filename, logger_name):\n",
    "    logger=turn_of_logger()\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    formatter=logging.Formatter(fmt='%(asctime)s,%(message)s',datefmt='%Y-%m-%d,%H:%M:%S')\n",
    "    #formatter=logging.Formatter(fmt='%(message)s')\n",
    "    fh=logging.FileHandler(filename)\n",
    "    fh.setFormatter(formatter)\n",
    "    logger.addHandler(fh)\n",
    "    return logger\n",
    "\n",
    "\n",
    "    # sh=logging.StreamHandler(sys.stdout)\n",
    "    # sh.setFormatter(formatter)\n",
    "    # logger.addHandler(sh)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ceab0bd-7982-4d37-a92a-157616c40fea",
   "metadata": {},
   "source": [
    "### ------------------------------- Reading and preparing data -----------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f603c19-23be-4857-91ed-8f728eb7437b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training=pd.read_parquet(\"./get_data/data_for_model_v2.parquet\")\n",
    "df_training.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26a113e-bac6-4055-9459-cc13f16330aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if index is sorted. if yes ==Ture\n",
    "df_training.datetime.is_monotonic_increasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3ce73e-f12f-4efb-86a4-e3ea0407c4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4943f69e-e221-407e-b92a-4ab47a1fc0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_training=df_training[(df_training.relevance_score>=0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de18eb5-c018-4dd6-9f62-098d15563f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_training.loc[0:1,['volume']]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da20d2ec-acef-414e-a380-191229a07b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Because I am not using all data, I can fill in with other value different from 0. The first value never will be 0.\n",
    "df_training['volume'] = df_training['volume'].replace(0, np.nan).ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbd0469-a502-4a21-8f91-1234785739e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check 80% of split in days\n",
    "split_value=int(len(df_training)*0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b2a3dd-5cbb-4df8-a7b3-727a08251390",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training.iloc[split_value-1:split_value,:]['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8ce406-703e-4764-8b87-19062a383b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter the dates where sentiment is not available\n",
    "\n",
    "#Select Validation first\n",
    "df_validation=df_training[(df_training.date>=datetime.date(2023,11,18))&(df_training.date<=datetime.date(2024,4,25))]\n",
    "print(\"Validation: \",df_validation.shape)\n",
    "#check if index is sorted. if yes ==Ture\n",
    "print(df_validation.datetime.is_monotonic_increasing)\n",
    "# selece Traning second -check to improve this\n",
    "df_training=df_training[(df_training.date>=datetime.date(2022,1,1))&(df_training.date<datetime.date(2023,11,17))]\n",
    "print(\"Training: \",df_training.shape)\n",
    "#check if index is sorted. if yes ==Ture\n",
    "print(df_training.datetime.is_monotonic_increasing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb524c59-e77f-40f3-a992-e8a3553edc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c43146-3b01-41c7-b8b4-675357ee58ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- arrange columns-----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa63ace-9a4a-491f-8ab6-520abbf6b198",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1=list(df_training.columns)[2:55] #remove ticker, datetime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0946ec-11c1-4856-b03f-c5a018164ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88500001-ef18-4069-b744-4e30481cd6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training=df_training[l1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780cdf26-271f-4ea4-a831-0d647b96865a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation=df_validation[l1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa33cf2-3449-43fa-a7a8-96755bb47226",
   "metadata": {},
   "outputs": [],
   "source": [
    " #---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6eef46-5525-4917-aa39-327e80efb116",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _remove_linear_tendecy (x):\n",
    "    return np.ediff1d(x, to_begin=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a133fff-04d1-4480-92d5-2d61fcf141a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _simple_net_return (x):\n",
    "    \"\"\"\n",
    "        Fractional change between the current and a prior element.\n",
    "        Computes the fractional change from the immediately previous row by default. \n",
    "        This is useful in comparing the fraction of change in a time series of elements.\n",
    "    \"\"\"\n",
    "    result=x.pct_change()\n",
    "    result.fillna(0,inplace=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5daf4d76-544b-4941-98e6-75ccd73226c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _log_return (x):\n",
    "    result=np.log(x/x.shift(1))\n",
    "    result.fillna(0,inplace=True)\n",
    "    return (result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f21c54-c173-401d-a379-7b897e8ba5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " #---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885e891a-0abd-4845-8b32-0e434bd286d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #df_training is a DataFrame with columns : \"open\", \"high\", \"low\", \"close\", \"Volume USD\"\n",
    "for dataframe in ['df_training','df_validation']:\n",
    "    #---------------------------------------------------------------------\n",
    "    #eval(dataframe)[\"feature_nweek\"] = eval(dataframe)[\"n_weekday\"]\n",
    "    #eval(dataframe)[\"feature_holiday\"] =  eval(dataframe)[\"holidays\"]\n",
    "    eval(dataframe)[\"feature_nhour\"] =  eval(dataframe)[\"n_hour\"]\n",
    "    \n",
    "    #Create the feature : ( close[t] - close[t-1] )/ close[t-1]\n",
    "    #df_training[\"diff_close\"] = df_training['close'].diff()\n",
    "    #eval(dataframe)[\"feature_close\"] = ( eval(dataframe)[\"close\"]) /  eval(dataframe)[\"close\"].abs().max() \n",
    "    #eval(dataframe)[\"feature_close\"] = _remove_linear_tendecy(eval(dataframe)[\"close\"]) \n",
    "    #eval(dataframe)[\"feature_close\"] = _simple_net_return(eval(dataframe)[\"close\"]) \n",
    "    eval(dataframe)[\"feature_close\"] = _log_return(eval(dataframe)[\"close\"]) \n",
    "    \n",
    "    # Create the feature : open[t] / close[t]\n",
    "    eval(dataframe)[\"feature_open\"] = _log_return(eval(dataframe)[\"open\"]) \n",
    "    #eval(dataframe)[\"feature_open\"] = ( eval(dataframe)[\"open\"])/  eval(dataframe)[\"close\"].abs().max() \n",
    "    \n",
    "    # Create the feature : high[t] / close[t]\n",
    "    eval(dataframe)[\"feature_high\"] = _log_return(eval(dataframe)[\"high\"]) \n",
    "    #eval(dataframe)[\"feature_high\"] = ( eval(dataframe)[\"high\"])/  eval(dataframe)[\"close\"].abs().max() \n",
    "    \n",
    "    # Create the feature : low[t] / close[t]\n",
    "    eval(dataframe)[\"feature_low\"] = _log_return(eval(dataframe)[\"low\"]) \n",
    "    #eval(dataframe)[\"feature_low\"]= ( eval(dataframe)[\"low\"])/  eval(dataframe)[\"close\"].abs().max() \n",
    "    \n",
    "    #eval(dataframe)[\"feature_volume\"] =  eval(dataframe)[\"volume\"].apply(lambda x: np.log(x) if x!=0 else x)/  eval(dataframe)[\"close\"].abs().max() \n",
    "    eval(dataframe)[\"feature_volume\"] = _log_return(eval(dataframe)[\"volume\"])     \n",
    "    #eval(dataframe)[\"feature_volume\"] =  eval(dataframe)[\"volume\"]/  (eval(dataframe)[\"close\"].abs().max()*1000000)\n",
    "    #create columns for  relevance_score (x) and ticket_sentiment_score (y)\n",
    "    # l1 is from 11 to 55 because I am selecting from score20_x to score1_y\n",
    "    for column in l1[11:55]:\n",
    "        column_name=\"feature_\"+column\n",
    "        eval(dataframe)[column_name]= eval(dataframe)[column] \n",
    "    #---------------------------------------------------------------------\n",
    "    #eval(dataframe).dropna(inplace= True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a379f18f-b5e9-4ace-ae7d-5a56d6d64a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list=[ x for x in list(df_training.columns) if \"feature_\" in x] #find all features in columns\n",
    "print(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e8a0e2-0883-466f-97de-d2c266008107",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f892b1-aa71-434f-8676-9f29208ef9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#---------------------------- check for Nulls & NAN _ relevance_score -------------------\n",
    "l1=list(df_training.columns)[11:55]\n",
    "serie_1=df_training[l1].isna().sum()\n",
    "serie_2=df_training[l1].isnull().sum()\n",
    "pd.concat( [serie_1, serie_2], join='outer',keys = ['Nan','Null'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3bc20c-f325-4dc8-a51b-c47d1603a16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check validation notna in close columns\n",
    "df_validation.feature_close.notna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73296e64-5879-41dd-8038-c46d4268ace3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training: \",df_training.shape)\n",
    "print(\"Validation: \",df_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a1b96b-41eb-410e-be1c-d7d3610a5346",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfde519-11ee-4320-9dab-663ed18aa38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if index is sorted. if yes ==Ture\n",
    "df_training.index.is_monotonic_increasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f356631-5aee-4f96-83b7-4f64376ad3cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c6a975-b4d7-4aff-87aa-682c00d8b7bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c151ff-abe9-47fb-a2b6-372c31c739d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check folders to save output\n",
    "import datetime\n",
    "    \n",
    "YEAR        = str(datetime.date.today().year)     # the current year\n",
    "MONTH       = str(datetime.date.today().month)   # the current month\n",
    "DATE        = str(datetime.date.today().day)      # the current day\n",
    "HOUR        = str(datetime.datetime.now().hour)   # the current hour\n",
    "MINUTE      = str(datetime.datetime.now().minute) # the current minute\n",
    "#SECONDS     = datetime.datetime.now().second #the current second\n",
    "string_folder=YEAR+MONTH+DATE+\"_\"+HOUR+MINUTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd45064f-cf25-457c-b990-e2da8fb041ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1648e6f3-b15c-458f-a348-18fca7c8e67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './output/'+string_folder+'/'\n",
    "if not os.path.exists(PATH):\n",
    "    os.makedirs(PATH)\n",
    "    # Creating folders for best DQN agents\n",
    "    PATH_EVAL=PATH+'agent_best_eval_models'+'/'\n",
    "    PATH_NEXT=PATH+'agent_best_next_models'+'/'\n",
    "    os.makedirs(PATH_EVAL)\n",
    "    os.makedirs(PATH_NEXT)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cfa6fa-f6f2-4d86-9132-973ba49bc4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logger=initLogging(PATH+\"output.log\",\"output\")\n",
    "logger.info('i,market_return,pr,Sharpe,score,avg_score,best_score,loss,n_steps,pr_val,score_val, avg_score_val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429cacf2-1754-4105-af59-4a1652400359",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_GAMES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c12be8d-4441-4d99-a263-117c9952be00",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    tf.compat.v1.disable_eager_execution() #improve \n",
    "    #manage_memory()\n",
    "    # #----------------Training----------------\n",
    "    # env = TradingEnv(\n",
    "    #     name= \"AAPL\",\n",
    "    #     df = df_training, # Your dataset with your custom features\n",
    "    #     positions = [0, 1], # -1 (=SHORT), 0(=OUT), +1 (=LONG)\n",
    "    #     portfolio_initial_value=100,\n",
    "    #     initial_position=1,\n",
    "        \n",
    "    #     obs_columns=feature_list, #automatically set columns as input\n",
    "        \n",
    "    #     #trading_fees = 0.01/100, # 0.01% per stock buy / sell (Binance fees)\n",
    "    #     trading_fees =0,\n",
    "    #     #borrow_interest_rate= 0.0003/100, # 0.0003% per timestep (one timestep = 1h here)\n",
    "    #     borrow_interest_rate= 0,\n",
    "    #     verbose=1\n",
    "    # )\n",
    "    #----------------Validation----------------\n",
    "    env_val = TradingEnv(\n",
    "        name= \"AAPL\",\n",
    "        df = df_validation, # Your dataset with your custom features\n",
    "        positions = [0, 1], # -1 (=SHORT), 0(=OUT), +1 (=LONG)\n",
    "        portfolio_initial_value=100,\n",
    "        initial_position=1,\n",
    "\n",
    "        obs_columns=feature_list, #automatically set columns as input\n",
    "        \n",
    "        trading_fees =0,\n",
    "        borrow_interest_rate= 0,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    best_score = -np.inf\n",
    "    load_checkpoint = False\n",
    "    record_agent = False\n",
    "    n_games = NUMBER_GAMES\n",
    "    # Epsilon should be in 0 because I need the agent's brain tries to predidct and it must not select action by random.\n",
    "    agent_brain = Agent(gamma=0.99, epsilon=1, lr=0.001,\n",
    "                  #input_dims=env.observation_space.shape,n_actions=env.action_space.n, \n",
    "                  input_dims=env_val.observation_space,n_actions=len(env_val.action_space),\n",
    "                  mem_size=1000000, eps_min=0.01,\n",
    "                  batch_size=16, replace=1000, eps_dec=1e-3, # batch_size=32 ATTENTION\n",
    "                  n_neurons1=256,n_neurons2=256,\n",
    "                  dir=PATH_EVAL, dir2=PATH_NEXT,\n",
    "                  env_name='Trading_bot')\n",
    "    \n",
    "    agent_brain.policy_net = tf.keras.models.load_model('./output/2024425_1349/model_q_eval.h5')\n",
    "    print('... models loaded successfully ...')\n",
    "    n_steps = 0\n",
    "   \n",
    "    scores, eps_history, steps_array, losses,portfolios = [], [], [], [],[]\n",
    "    \n",
    "    for i in range(n_games):\n",
    "        done = False\n",
    "        score = 0\n",
    "    \n",
    "        terminated = False\n",
    "        truncated =False\n",
    "        done=(terminated|truncated)\n",
    "        #actual_obs=env.reset(seed=7)[0]# I had to do this because array is not two parameters due to new gym version\n",
    "        actual_obs,info=env_val.reset(seed=395)\n",
    "        print(actual_obs)\n",
    "        while not done: #playing one game.\n",
    "            action = agent_brain.choose_action(actual_obs,False)\n",
    "            #print(\"env.step_action \",action)\n",
    "            new_obs, reward, terminated,truncated,info = env_val.step(action)\n",
    "            #----------------------------------------------------------------------\n",
    "            #   New GYM version needs to create done from Terminadted and Truncated (after 200)\n",
    "            done=(terminated|truncated)\n",
    "            #-----------------------------------------------------------------------    \n",
    "            score += reward\n",
    "    \n",
    "            #print(actual_obs)\n",
    "            agent_brain.store_transition(actual_obs, action,reward, new_obs, done)\n",
    "        \n",
    "            #--------------------------------------\n",
    "            #New observaction is tronsformed to actual_obs\n",
    "            actual_obs = new_obs\n",
    "            #-----------------------------------------\n",
    "            #-----------------------------------------\n",
    "            # start to train\n",
    "            #loss=agent.learn()\n",
    "            loss=0\n",
    "            #------------------------------------------\n",
    "            n_steps += 1\n",
    "    \n",
    "        eps_history.append(agent_brain.epsilon)\n",
    "        scores.append(score)\n",
    "        losses.append(loss)\n",
    "        print(\"Score: \", score, \" Loss: \", loss)\n",
    "        steps_array.append(n_steps)\n",
    "    \n",
    "        #This is the average score. From the last 100 scores\n",
    "        avg_score = np.mean(scores[-100:])\n",
    "        market_return=(100*(env_val.df.loc[env_val._idx,'close'] / env_val.df.loc[0,'close'] -1))\n",
    "        pr=(100*(env_val.df.loc[env_val._idx,'portfolio_valuation'] / env_val.df.loc[0,'portfolio_valuation'] -1))\n",
    "        portfolios.append(pr)\n",
    "        print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "        print('episode {} score {:.1f} avg score {:.1f} best score {:.1f} loss {:.1f} epsilon {:.2f} steps {} MarketReturn {:.2f} PortfolioReturn {:.2f} '\\\n",
    "              .format(i, score, avg_score, best_score,loss, agent_brain.epsilon,n_steps,market_return,pr))\n",
    "        print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "        if score > best_score:\n",
    "            if not load_checkpoint:\n",
    "                agent_brain.save_models()\n",
    "            best_score = score\n",
    "        if i % 5 == 0:\n",
    "            agent_brain.target_net.set_weights(agent_brain.policy_net.get_weights())\n",
    "            print('Target_net has changed...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea14b85-782d-4bf5-abd4-995f72bc6683",
   "metadata": {},
   "outputs": [],
   "source": [
    "#aux_df.to_csv(PATH+\"output_dataframe.csv\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5cd4e7-4b11-432f-bdca-be58997a3413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = [i+1 for i in range(len(scores))]\n",
    "# agent_brain.policy_net.save(PATH+'model_q_eval.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a83f996-59ec-430e-b8f0-bc47e28ae79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e1b755-0f3c-4ba7-976a-4f0ea97e1a35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e6ea54-0259-4c51-8235-baf954ec6ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.df.to_csv(f\"{PATH}df_{string_folder}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ac9076-5452-4425-9ad8-9ac58fe35c28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0253a19-2dc2-45c1-9649-3c71c273501d",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dfa8c4-0ee3-478a-954f-7fa2033ccf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_val.df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99eb181d-4f24-4def-97d1-e2b808072ed5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c5c175-59f7-46d3-ac72-e177b5f99299",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d60a69-5380-4f01-b351-2b1736baab0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
